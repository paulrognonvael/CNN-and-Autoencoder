
> #Flags
> 
> #Flags
> FLAGS <- flags(
+   flag_numeric("filters_nb_start", 32),
+   flag_numeric("pooling_size", 2)
+ )

> #train and validation data
> train_datagen <- image_data_generator(rescale = 1/255)

> train_generator <- flow_images_from_directory(
+   train_dir,
+   train_datagen,
+   color_mode = "grayscale",
+   target_size = c(64, 64),
+   batc .... [TRUNCATED] 

> validation_datagen <- image_data_generator(rescale = 1/255)

> validation_generator <- flow_images_from_directory(
+   validation_dir,
+   validation_datagen,
+   color_mode = "grayscale",
+   target_size = c(64 .... [TRUNCATED] 

> #### Convolutional Encoder
> model_enc <- keras_model_sequential() 

> model_enc %>%
+   layer_conv_2d(filters = FLAGS$filters_nb_start, kernel_size = c(2,2), padding ="same",
+                 activation = "relu",input .... [TRUNCATED] 

> #### Convolutional Decoder 
> 
> model_dec <- keras_model_sequential() 

> model_dec %>%
+   layer_conv_2d(filters = FLAGS$filters_nb_start/2, kernel_size = c(3,3), 
+                 activation = "relu", padding = "same",
 .... [TRUNCATED] 

> summary(model_dec)
Model: "sequential_52"
__________________________________________________________________________
Layer (type)                     Output Shape                 Param #     
==========================================================================
conv2d_150 (Conv2D)              (None, 4, 4, 64)             36928       
__________________________________________________________________________
up_sampling2d_31 (UpSampling2D)  (None, 8, 8, 64)             0           
__________________________________________________________________________
conv2d_151 (Conv2D)              (None, 8, 8, 128)            73856       
__________________________________________________________________________
up_sampling2d_32 (UpSampling2D)  (None, 16, 16, 128)          0           
__________________________________________________________________________
conv2d_152 (Conv2D)              (None, 16, 16, 128)          147584      
__________________________________________________________________________
up_sampling2d_33 (UpSampling2D)  (None, 64, 64, 128)          0           
__________________________________________________________________________
conv2d_153 (Conv2D)              (None, 64, 64, 1)            129         
==========================================================================
Total params: 258,497
Trainable params: 258,497
Non-trainable params: 0
__________________________________________________________________________

> #### Autoencoder 
> model_auto<-keras_model_sequential()

> model_auto %>%model_enc%>%model_dec
Model
Model: "sequential_53"
__________________________________________________________________________
Layer (type)                     Output Shape                 Param #     
==========================================================================
sequential_51 (Sequential)       (None, 4, 4, 64)             99136       
__________________________________________________________________________
sequential_52 (Sequential)       (None, 64, 64, 1)            258497      
==========================================================================
Total params: 357,633
Trainable params: 357,633
Non-trainable params: 0
__________________________________________________________________________



> #batch size
> b_size <- 50

> # set seed for reproductibility
> set.seed(42)

> tensorflow::tf$random$set_seed(42)

> #initialise the model
> model_auto %>% compile(
+   loss = "mean_squared_error",
+   #optimizer = optimizer_rmsprop(),
+   optimizer = "adam",
+   m .... [TRUNCATED] 

> # Fit the model
> history_auto <- model_auto %>% fit_generator(
+   train_generator,
+   steps_per_epoch = 500/b_size,
+   epochs = 5,
+   validatio .... [TRUNCATED] 

> model_auto %>% save_model_hdf5("auto_model.h5")

> train_datagen <- image_data_generator(rescale = 1/255)

> train_generator <- flow_images_from_directory(
+   train_dir,
+   train_datagen,
+   color_mode = "grayscale",
+   target_size = c(64, 64),
+   batc .... [TRUNCATED] 

> test_datagen <- image_data_generator(rescale = 1/255)

> test_generator <- flow_images_from_directory(
+   test_dir,
+   test_datagen,
+   color_mode = "grayscale",
+   target_size = c(64, 64),
+   batch_s .... [TRUNCATED] 

> # From input to encoder - training
> predict_enc_train <- model_enc %>% predict_generator(
+   train_generator,
+   steps = 500/b_size)

> dim(predict_enc_train)
[1] 500   4   4  64

> # From input to encoder - test
> predict_enc_test <- model_enc %>% predict_generator(
+   test_generator,
+   steps = 100/b_size)

> dim(predict_enc_test)
[1] 100   4   4  64

> # flat file 
> dim(predict_enc_train) <- c(nrow(predict_enc_train),prod(dim(predict_enc_train)[-1]))

> dim(predict_enc_test) <- c(nrow(predict_enc_test),prod(dim(predict_enc_test)[-1]))

> # Flatten array 
> y_radio_train <- train_generator$classes

> y_radio_test <- stat_df_bestbatch_aug$class

> save(predict_enc_train,y_radio_train,predict_enc_test, y_radio_train, file=paste0("Conv_Encod_Flat_filter",
+                                        .... [TRUNCATED] 
